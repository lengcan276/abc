# agents/feature_agent.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
import os
import re
from collections import Counter
import warnings
import logging
import re

class FeatureAgent:
    """
    Agent responsible for feature engineering, including generating
    alternative 3D descriptors from molecular structure information.
    """
    
    def __init__(self, data_file=None):
        """Initialize the FeatureAgent with input data file."""
        self.data_file = data_file
        self.df = None
        self.feature_df = None
        self.alt_3d_features = None
        self.reversed_gap_df = None  # 新增：存储反转能隙数据
        self.output_dir = '/vol1/home/lengcan/cleng/Function_calling/test/0-ground_state_structures/0503/reverse_TADF_system_deepreseach_0617/data/extracted'  # 新增：输出目录
        self.setup_logging()
        
    def setup_logging(self):
        """Configure logging for the feature agent."""
        logging.basicConfig(level=logging.INFO, 
                           format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                           filename='/vol1/home/lengcan/cleng/Function_calling/test/0-ground_state_structures/0503/reverse_TADF_system_deepreseach_0617/data/logs/feature_agent.log')
        self.logger = logging.getLogger('FeatureAgent')
        
    def load_data(self, file_path=None):
        """Load molecular data from CSV file."""
        if file_path:
            self.data_file = file_path
            
        if not self.data_file or not os.path.exists(self.data_file):
            self.logger.error(f"Data file not found: {self.data_file}")
            return False
            
        print(f"Loading data from {self.data_file}...")
        self.df = pd.read_csv(self.data_file)
        
        # 检查是详细数据文件还是汇总数据文件
        if 'State' in self.df.columns:
            # 如果是 all_conformers_data.csv
            print(f"Dataset shape: {self.df.shape}")
            print(f"Number of molecules: {self.df['Molecule'].nunique()}")
            print(f"Number of states: {self.df['State'].nunique()}")
            print(f"States available: {self.df['State'].unique()}")
            
            # Check excited state data availability
            excited_count = self.df['excited_energy'].notna().sum() if 'excited_energy' in self.df.columns else 0
            print(f"Number of entries with excited state data: {excited_count}")
        else:
            # 如果是 molecular_properties_summary.csv
            print(f"Dataset shape: {self.df.shape}")
            print(f"Number of molecules: {self.df['Molecule'].nunique()}")
            
            # 识别状态相关列
            state_prefixes = ['neutral_', 'cation_', 'triplet_']
            print(f"Number of states: {len(state_prefixes)}")
            print(f"States available: {state_prefixes}")
            
            # 检查关键特征的可用性
            excited_columns = [col for col in self.df.columns if 'excited_' in col or 's1_' in col or 't1_' in col]
            print(f"Number of excited state properties: {len(excited_columns)}")
            
            # 创建虚拟状态数据框（如果后续处理需要）
            self.create_virtual_states()
        
        return True
    def select_features(self, target_col, n_features=15):
        """在FeatureAgent中选择最相关的特征"""
        from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression
        
        if not hasattr(self, 'feature_df') or self.feature_df is None:
            print("警告：FeatureAgent没有加载数据。")
            return None
            
        # 保留有目标值的数据
        df_target = self.feature_df[self.feature_df[target_col].notna()].copy()
        
        if len(df_target) < 10:
            print(f"警告：目标{target_col}的样本太少。")
            return None
            
        # 确定可用于训练的特征
        exclude_cols = ['Molecule', 'conformer', 'State', 'is_primary',
                    target_col, 'excited_energy', 'excited_opt_success',
                    'excited_no_imaginary', 'excited_homo', 'excited_lumo',
                    'excited_homo_lumo_gap', 'excited_dipole']
        
        # 选择数值特征
        numeric_cols = df_target.select_dtypes(include=['float64', 'int64']).columns
        feature_cols = [col for col in numeric_cols if col not in exclude_cols]
        
        # 处理余下特征选择逻辑...
        
        # 返回选择的特征
        return {
            'features': feature_cols[:n_features]  # 简单返回前n个特征
        }

    def compute_derived_features(self):
        """计算衍生特征，包括gap相关的交互特征"""
        if self.feature_df is None:
            self.logger.error("No features to compute derived features.")
            return
            
        print("Computing derived features...")
        
        # 1. 原有的衍生特征
        # HOMO与极性的交互
        if 'homo' in self.feature_df.columns and 'estimated_polarity' in self.feature_df.columns:
            self.feature_df['homo_polarity'] = self.feature_df['homo'] * self.feature_df['estimated_polarity']
        
        # LUMO与电子效应的交互
        if 'lumo' in self.feature_df.columns and 'net_electronic_effect' in self.feature_df.columns:
            self.feature_df['lumo_electronic_effect'] = self.feature_df['lumo'] * self.feature_df['net_electronic_effect']
        
        # HOMO-LUMO gap与共轭的关系
        if 'homo_lumo_gap' in self.feature_df.columns and 'estimated_conjugation' in self.feature_df.columns:
            self.feature_df['gap_conjugation'] = self.feature_df['homo_lumo_gap'] * self.feature_df['estimated_conjugation']
            # 避免除零
            conjugation_safe = self.feature_df['estimated_conjugation'].replace(0, 0.1)
            self.feature_df['gap_conjugation_ratio'] = self.feature_df['homo_lumo_gap'] / conjugation_safe
        
        # 偶极矩与平面性
        if 'dipole' in self.feature_df.columns and 'planarity_index' in self.feature_df.columns:
            self.feature_df['dipole_planarity'] = self.feature_df['dipole'] * self.feature_df['planarity_index']
        
        # 能量归一化
        if 'energy' in self.feature_df.columns and 'estimated_size' in self.feature_df.columns:
            size_safe = self.feature_df['estimated_size'].replace(0, 1)
            self.feature_df['energy_per_size'] = self.feature_df['energy'] / size_safe
        
        # 2. 新增：Gap相关的衍生特征
        # 找出所有的gap列
        gap_columns = [col for col in self.feature_df.columns 
                       if col.endswith('_gap') and not col.endswith('_gap_meV')]
        
        for gap_col in gap_columns:
            gap_type = gap_col.replace('_gap', '')
            
            # Gap与HOMO-LUMO gap的比率
            if 'homo_lumo_gap' in self.feature_df.columns:
                hl_safe = self.feature_df['homo_lumo_gap'].replace(0, 0.1)
                self.feature_df[f'{gap_type}_vs_HL_ratio'] = self.feature_df[gap_col] / hl_safe
            
            # Gap与电子效应的交互
            if 'electron_withdrawing_effect' in self.feature_df.columns:
                self.feature_df[f'{gap_type}_x_EWG'] = self.feature_df[gap_col] * self.feature_df['electron_withdrawing_effect']
            
            if 'electron_donating_effect' in self.feature_df.columns:
                self.feature_df[f'{gap_type}_x_EDG'] = self.feature_df[gap_col] * self.feature_df['electron_donating_effect']
            
            # Gap与共轭的交互
            if 'estimated_conjugation' in self.feature_df.columns:
                self.feature_df[f'{gap_type}_x_conjugation'] = self.feature_df[gap_col] * self.feature_df['estimated_conjugation']
            
            # Gap与极性的交互
            if 'estimated_polarity' in self.feature_df.columns:
                self.feature_df[f'{gap_type}_x_polarity'] = self.feature_df[gap_col] * self.feature_df['estimated_polarity']
        
        # 3. 新增：基于最负gap的特征
        if 'most_negative_gap_value' in self.feature_df.columns:
            # 最负gap与各种分子性质的关系
            if 'homo' in self.feature_df.columns:
                self.feature_df['most_neg_gap_x_homo'] = self.feature_df['most_negative_gap_value'] * self.feature_df['homo']
            
            if 'dipole' in self.feature_df.columns:
                self.feature_df['most_neg_gap_x_dipole'] = self.feature_df['most_negative_gap_value'] * self.feature_df['dipole']
            
            # 创建gap严重程度指标
            self.feature_df['gap_severity'] = self.feature_df['most_negative_gap_value'].apply(
                lambda x: 0 if pd.isna(x) or x >= 0 else abs(x)
            )
            
            # Gap严重程度分类
            self.feature_df['gap_severity_category'] = pd.cut(
                self.feature_df['gap_severity'],
                bins=[0, 0.01, 0.05, 0.1, np.inf],
                labels=['none', 'weak', 'moderate', 'strong']
            )
        
        # 4. 新增：多gap统计特征
        if 'num_inverted_gaps' in self.feature_df.columns:
            # 反转密度（每个激发态的反转概率）
            total_states = self.feature_df.get('num_singlet_states', 1) + self.feature_df.get('num_triplet_states', 1)
            self.feature_df['inversion_density'] = self.feature_df['num_inverted_gaps'] / total_states.replace(0, 1)
        
        # 5. 电荷和共轭的组合效应
        if 'charge_spread' in self.feature_df.columns and 'estimated_conjugation' in self.feature_df.columns:
            self.feature_df['charge_conjugation'] = self.feature_df['charge_spread'] * self.feature_df['estimated_conjugation']
        
        # 6. 替代基复杂度评分
        substituent_cols = [col for col in self.feature_df.columns if col.endswith('_count')]
        if substituent_cols:
            self.feature_df['substituent_diversity'] = (self.feature_df[substituent_cols] > 0).sum(axis=1)
            self.feature_df['total_substituents'] = self.feature_df[substituent_cols].sum(axis=1)
        
        # 7. 环境敏感性指标
        if all(col in self.feature_df.columns for col in ['dipole', 'estimated_polarity', 'charge_spread']):
            self.feature_df['environment_sensitivity'] = (
                self.feature_df['dipole'] * 0.4 + 
                self.feature_df['estimated_polarity'] * 0.3 + 
                self.feature_df['charge_spread'] * 0.3
            )
        
        print(f"Computed {len(self.feature_df.columns) - len(gap_columns)} derived features")
        print(f"Total features now: {len(self.feature_df.columns)}")
        
        # 移除可能产生的重复列
        self.feature_df = self.feature_df.loc[:, ~self.feature_df.columns.duplicated()]
        
        return self.feature_df
    def generate_molecular_descriptors(self):
        """Generate molecular descriptors from the loaded data."""
        if self.df is None:
            self.logger.error("No data loaded. Call load_data() first.")
            return
            
        print("Generating molecular descriptors...")
        
        # Select relevant columns for features
        feature_cols = []
        
        # Electronic properties
        electronic_cols = ['homo', 'lumo', 'homo_lumo_gap', 'dipole',
                          'excited_homo', 'excited_lumo', 'excited_homo_lumo_gap',
                          'excited_dipole', 'neutral_homo', 'neutral_lumo', 
                          'neutral_homo_lumo_gap', 'neutral_dipole']
        
        # Charge properties
        charge_cols = ['max_positive_charge', 'max_negative_charge', 
                      'charge_spread', 'avg_charge', 'neutral_max_positive_charge',
                      'neutral_max_negative_charge', 'neutral_charge_spread']
        
        # Energy properties
        energy_cols = ['energy', 'excited_energy', 'neutral_energy', 
                      'cation_energy', 'triplet_energy', 'ionization_energy_ev',
                      'triplet_gap_ev', 's1_energy_ev', 't1_energy_ev', 
                      's1_t1_gap_ev', 's1_t1_gap', 'excitation_energy_ev']
        
        # Oscillator strength and other excited state properties
        excited_cols = ['oscillator_strength', 'num_singlet_states', 
                       'num_triplet_states', 'num_inverted_gaps',
                       'primary_inversion_gap', 'primary_inversion_gap_meV']
        
        # Structural properties (if available from RDKit processing)
        structure_cols = ['num_atoms', 'num_bonds', 'mol_weight', 
                         'num_rotatable_bonds', 'formula']
        
        # CREST properties
        crest_cols = [col for col in self.df.columns if 'crest_' in col]
        
        # Combine all feature columns
        all_feature_cols = (electronic_cols + charge_cols + energy_cols + 
                           excited_cols + structure_cols + crest_cols)
        
        # Filter to only include columns that exist in the dataframe
        available_cols = [col for col in all_feature_cols if col in self.df.columns]
        
        # Create feature dataframe
        self.feature_df = self.df[['Molecule'] + available_cols].copy()
        
        # Convert boolean columns to numeric
        bool_cols = self.feature_df.select_dtypes(include=['bool']).columns
        for col in bool_cols:
            self.feature_df[col] = self.feature_df[col].astype(int)
            
        print(f"Generated {len(available_cols)} molecular descriptors")
        
        # Track which columns are related to excited states
        excited_columns = [col for col in available_cols 
                          if any(keyword in col for keyword in 
                                ['excited', 's1', 't1', 'oscillator', 'excitation'])]
        print(f"Number of excited state properties: {len(excited_columns)}")
        
        # 创建虚拟状态数据框（如果后续处理需要）
        self.create_virtual_states()
    def create_virtual_states(self):
        """创建虚拟状态数据框，将汇总数据转换为三个状态的格式"""
        # 初始化状态列表和结果列表
        states = ['neutral', 'cation', 'triplet']
        expanded_rows = []
        
        # 为每个分子创建三行（每个状态一行）
        for _, row in self.df.iterrows():
            molecule = row['Molecule']
            
            for state in states:
                prefix = f"{state}_"
                # 获取当前状态的所有列
                state_cols = {col.replace(prefix, ''): row[col] 
                            for col in self.df.columns 
                            if col.startswith(prefix)}
                
                # 添加基本信息
                new_row = {'Molecule': molecule, 'State': state}
                # 添加状态特定的列
                new_row.update(state_cols)
                
                # 对于中性状态，添加激发态信息
                if state == 'neutral' and 'excited_energy' in self.df.columns:
                    excited_cols = {col: row[col] 
                                for col in self.df.columns 
                                if 'excited_' in col or col in ['s1_energy_ev', 't1_energy_ev', 's1_t1_gap_ev']}
                    new_row.update(excited_cols)
                
                expanded_rows.append(new_row)
        
        # 创建虚拟状态数据框
        self.state_df = pd.DataFrame(expanded_rows)
        print(f"Created virtual state dataframe with shape: {self.state_df.shape}")
        
    def extract_alternative_3d_features(self):
        """
        Extract and create alternative 3D-related features from the dataset
        """
        print("Creating alternative 3D-related features...")
        
        if self.df is None:
            self.logger.error("No data loaded. Call load_data() first.")
            return None

        # Create a new DataFrame to store alternative features
        alt_features = pd.DataFrame()
        alt_features['Molecule'] = self.df['Molecule'].unique()

        # 1. Extract structural information from molecule names
        # Number and type of rings
        alt_features['ring_count'] = alt_features['Molecule'].apply(
            lambda x: x.lower().count('ring')
        )
        alt_features['has_5ring'] = alt_features['Molecule'].apply(
            lambda x: 1 if '5ring' in x.lower() else 0
        )
        alt_features['has_3ring'] = alt_features['Molecule'].apply(
            lambda x: 1 if '3ring' in x.lower() else 0
        )
        alt_features['has_7ring'] = alt_features['Molecule'].apply(
            lambda x: 1 if '7ring' in x.lower() else 0
        )

        # 2. Substituent position features
        alt_features['has_in_group'] = alt_features['Molecule'].apply(
            lambda x: 1 if '_in' in x.lower() else 0
        )
        alt_features['has_out_group'] = alt_features['Molecule'].apply(
            lambda x: 1 if '_out' in x.lower() else 0
        )
        alt_features['has_both_groups'] = alt_features['Molecule'].apply(
            lambda x: 1 if '_both' in x.lower() else 0
        )

        # 3. Create complex substituent features
        functional_groups = ['cn', 'nh2', 'oh', 'me', 'f', 'sh', 'bh2', 'cf3', 'no2', 'ome', 'nme2', 'nph3', 'nn+']
        for group in functional_groups:
            alt_features[f'has_{group}'] = alt_features['Molecule'].apply(
                lambda x: 1 if group in x.lower() else 0
            )
            # Count occurrences of each substituent
            alt_features[f'{group}_count'] = alt_features['Molecule'].apply(
                lambda x: x.lower().count(group)
            )

        # 4. Create molecular complexity indicators
        # Total number of substituents
        alt_features['total_substituents'] = 0
        for group in functional_groups:
            alt_features['total_substituents'] += alt_features[f'{group}_count']

        # Structural complexity - based on rings and substituents
        alt_features['structural_complexity'] = alt_features['ring_count'] + alt_features['total_substituents']

        # 5. Infer approximate molecular size
        # Assume each ring and substituent contributes a certain size
        ring_sizes = {'has_3ring': 3, 'has_5ring': 5, 'has_7ring': 7}
        alt_features['estimated_size'] = 0
        for ring, size in ring_sizes.items():
            alt_features['estimated_size'] += alt_features[ring] * size

        # Different substituents contribution to size
        group_sizes = {
            'cn_count': 2, 'nh2_count': 1.5, 'oh_count': 1, 'me_count': 1,
            'f_count': 0.5, 'sh_count': 1, 'bh2_count': 1, 'cf3_count': 3,
            'no2_count': 2, 'ome_count': 2, 'nme2_count': 3, 'nph3_count': 7, 'nn+_count': 2
        }
        for group, size in group_sizes.items():
            alt_features['estimated_size'] += alt_features[group] * size

        # Ensure estimated_size is at least 1, to avoid division by zero errors
        alt_features['estimated_size'] = alt_features['estimated_size'].apply(lambda x: max(1.0, x))

        # 6. Infer molecular polarity
        # Different groups' polarity contributions
        polarity_contributions = {
            'cn_count': 3.5, 'nh2_count': 3, 'oh_count': 3, 'f_count': 4,
            'sh_count': 1.5, 'no2_count': 4, 'ome_count': 2.5, 'nme2_count': 2,
            'nn+_count': 4.5, 'nph3_count': 1, 'cf3_count': 2.5, 'me_count': 0.2, 'bh2_count': 1
        }
        alt_features['estimated_polarity'] = 0
        for group, polarity in polarity_contributions.items():
            alt_features['estimated_polarity'] += alt_features[group] * polarity

        # 7. Infer hydrophobicity/hydrophilicity
        # Different groups' hydrophobicity contributions (positive more hydrophobic, negative more hydrophilic)
        hydrophobicity = {
            'cn_count': -1, 'nh2_count': -2, 'oh_count': -2, 'f_count': -0.5,
            'sh_count': 0.5, 'no2_count': -1.5, 'ome_count': -0.5, 'nme2_count': 0.5,
            'nn+_count': -3, 'nph3_count': 3, 'cf3_count': 2, 'me_count': 1, 'bh2_count': 0.5
        }
        alt_features['estimated_hydrophobicity'] = 0
        for group, hydro in hydrophobicity.items():
            alt_features['estimated_hydrophobicity'] += alt_features[group] * hydro

        # 8. Infer electronic effects
        # Different groups' electronic effects (+value electron-donating, -value electron-withdrawing)
        electronic_effects = {
            'cn_count': -3, 'nh2_count': 2, 'oh_count': 1, 'f_count': -1,
            'sh_count': 0.5, 'no2_count': -3.5, 'ome_count': 1, 'nme2_count': 2,
            'nn+_count': -3, 'nph3_count': 1.5, 'cf3_count': -2.5, 'me_count': 0.5, 'bh2_count': -1
        }
        alt_features['electron_donating_effect'] = 0
        alt_features['electron_withdrawing_effect'] = 0

        for group, effect in electronic_effects.items():
            if effect > 0:
                alt_features['electron_donating_effect'] += alt_features[group] * effect
            else:
                alt_features['electron_withdrawing_effect'] += alt_features[group] * abs(effect)

        # Ensure electron_withdrawing_effect is at least 0.1, to avoid division by zero
        alt_features['electron_withdrawing_effect'] = alt_features['electron_withdrawing_effect'].apply(
            lambda x: max(0.1, x)
        )

        # Net electronic effect
        alt_features['net_electronic_effect'] = alt_features['electron_donating_effect'] - alt_features['electron_withdrawing_effect']

        # 9. Estimate conjugation degree
        # Ring systems and certain substituents increase conjugation
        conjugation_contributors = {
            'has_5ring': 5, 'has_3ring': 3, 'has_7ring': 7,
            'cn_count': 2, 'nh2_count': 1, 'oh_count': 1, 'no2_count': 2,
            'nme2_count': 1, 'nn+_count': 1.5
        }

        alt_features['estimated_conjugation'] = 0
        for contrib, value in conjugation_contributors.items():
            alt_features['estimated_conjugation'] += alt_features[contrib] * value

        # 10. Predict stereochemical properties
        # Estimate 3D shape based on rings and substituents
        alt_features['planarity_index'] = 0

        # Planarity index: more rings increase planarity, certain substituents decrease it
        alt_features['planarity_index'] += alt_features['ring_count'] * 2
        alt_features['planarity_index'] -= alt_features['nph3_count'] * 3  # Large substituents decrease planarity
        alt_features['planarity_index'] -= alt_features['nme2_count'] * 1
        alt_features['planarity_index'] -= alt_features['cf3_count'] * 1.5

        # Ensure planarity index is not negative
        alt_features['planarity_index'] = alt_features['planarity_index'].apply(lambda x: max(0.1, x))

        print(f"Created {len(alt_features.columns) - 1} alternative 3D features for {len(alt_features)} molecules")
        
        self.alt_3d_features = alt_features
        return alt_features
        
    def preprocess_data(self):
        """Preprocess data and create features."""
        print("预处理数据并创建特征...")

        if self.df is None:
            self.logger.error("未加载数据。请先调用 load_data() 方法。")
            return None
            
        if self.alt_3d_features is None:
            self.extract_alternative_3d_features()

        # 首先进行简单的数据清洗
        feature_df = self.df.copy()
        
        # 检查是否有 State 列，如果没有，使用汇总数据处理方法
        has_state_column = 'State' in feature_df.columns
        
        if not has_state_column:
            print("检测到汇总数据格式 (molecular_properties_summary.csv)，进行适配处理...")
            
            # 创建一个空的临时数据框，用于存储展开后的数据
            expanded_data = []
            
            # 为每个分子创建三个状态的行
            for _, row in feature_df.iterrows():
                molecule = row['Molecule']
                
                # 创建中性状态行
                neutral_row = {
                    'Molecule': molecule,
                    'State': 'neutral',
                    'is_primary': True  # 假设每个状态的主要构象体
                }
                
                # 添加中性状态的特定列
                neutral_prefix = 'neutral_'
                for col in feature_df.columns:
                    if col.startswith(neutral_prefix):
                        # 去掉前缀，添加到新行
                        neutral_row[col.replace(neutral_prefix, '')] = row[col]
                
                # 添加激发态列（不带前缀）
                for col in ['excited_energy', 'excited_opt_success', 'excited_homo', 
                            'excited_lumo', 'excited_homo_lumo_gap', 'excited_dipole',
                            's1_energy_ev', 'oscillator_strength', 't1_energy_ev', 
                            's1_t1_gap_ev', 'excitation_energy_ev']:
                    if col in feature_df.columns:
                        neutral_row[col] = row[col]
                
                # 创建阳离子状态行
                cation_row = {
                    'Molecule': molecule,
                    'State': 'cation',
                    'is_primary': True
                }
                
                # 添加阳离子状态的特定列
                cation_prefix = 'cation_'
                for col in feature_df.columns:
                    if col.startswith(cation_prefix):
                        cation_row[col.replace(cation_prefix, '')] = row[col]
                
                # 创建三重态状态行
                triplet_row = {
                    'Molecule': molecule,
                    'State': 'triplet',
                    'is_primary': True
                }
                
                # 添加三重态状态的特定列
                triplet_prefix = 'triplet_'
                for col in feature_df.columns:
                    if col.startswith(triplet_prefix):
                        triplet_row[col.replace(triplet_prefix, '')] = row[col]
                
                # 将三个行添加到展开的数据中
                expanded_data.append(neutral_row)
                expanded_data.append(cation_row)
                expanded_data.append(triplet_row)
            
            # 创建展开后的数据框
            feature_df = pd.DataFrame(expanded_data)
            print(f"已将汇总数据转换为详细格式，共 {len(feature_df)} 行")
        
        # 检查是否包含结构特征
        structure_columns = [
            'conjugation_path_count', 'max_conjugation_length', 
            'dihedral_angles_count', 'max_dihedral_angle', 'avg_dihedral_angle',
            'twisted_bonds_count', 'twist_ratio',
            'hydrogen_bonds_count', 'avg_h_bond_strength', 'max_h_bond_strength',
            'planarity', 'aromatic_rings_count'
        ]
        
        has_structure_data = any(col in feature_df.columns for col in structure_columns)
        
        # 如果没有结构数据，可以提供警告
        if not has_structure_data:
            print("警告：数据中未包含分子结构特征。部分分析功能将受限。")
        else:
            print(f"检测到分子结构特征，包含 {sum(1 for col in structure_columns if col in feature_df.columns)} 种结构特征。")
            # 为结构特征创建衍生特征
            if 'max_dihedral_angle' in feature_df.columns:
                # 创建扭曲类别特征
                feature_df['twist_category'] = pd.cut(
                    feature_df['max_dihedral_angle'],
                    bins=[0, 20, 40, 60, 90],
                    labels=['低扭曲 (<20°)', '中等扭曲 (20-40°)', '高扭曲 (40-60°)', '极高扭曲 (>60°)']
                )
                
            if 'max_conjugation_length' in feature_df.columns:
                # 创建共轭长度类别
                feature_df['conjugation_category'] = pd.cut(
                    feature_df['max_conjugation_length'],
                    bins=[0, 5, 10, 15, float('inf')],
                    labels=['短共轭 (<5)', '中等共轭 (5-10)', '长共轭 (10-15)', '超长共轭 (>15)']
                )
                
            if 'hydrogen_bonds_count' in feature_df.columns:
                # 创建氢键类别
                feature_df['h_bond_category'] = pd.cut(
                    feature_df['hydrogen_bonds_count'],
                    bins=[-1, 0, 2, float('inf')],
                    labels=['无氢键', '少量氢键 (1-2)', '多氢键 (>2)']
                )
        
        # 创建新特征
        # 1. 能量差异特征
        if 'energy' in feature_df.columns:
            # 计算中性状态与其他状态之间的能量差异
            # 按分子分组
            molecule_groups = feature_df.groupby('Molecule')

            # 创建一个字典来存储中性状态能量
            neutral_energies = {}
            for molecule, group in molecule_groups:
                neutral_group = group[group['State'] == 'neutral']
                if not neutral_group.empty and 'energy' in neutral_group.columns:
                    # 获取最低能量构象体 (primary=True)
                    primary_neutral = neutral_group[neutral_group['is_primary'] == True]
                    if not primary_neutral.empty:
                        neutral_energies[molecule] = primary_neutral['energy'].values[0]
                    else:
                        # 如果没有 primary=True 构象体，使用能量最低的
                        neutral_energies[molecule] = neutral_group['energy'].min()

            # 计算与中性状态的能量差异
            feature_df['energy_diff_from_neutral'] = feature_df.apply(
                lambda row: row['energy'] - neutral_energies.get(row['Molecule'], np.nan)
                if row['Molecule'] in neutral_energies else np.nan, axis=1
            )

        # 2. 添加 HOMO-LUMO 能隙特征
        if 'homo' in feature_df.columns and 'lumo' in feature_df.columns:
            # 确保所有值都是数值型
            feature_df['homo_num'] = pd.to_numeric(feature_df['homo'], errors='coerce')
            feature_df['lumo_num'] = pd.to_numeric(feature_df['lumo'], errors='coerce')
            feature_df['gap_calculated'] = feature_df['lumo_num'] - feature_df['homo_num']

        # 3. CREST 特征
        # 从 CREST 数据中提取信息
        if 'crest_num_conformers' in feature_df.columns:
            # 更多构象体意味着更高的构象灵活性
            feature_df['conformational_flexibility'] = np.log1p(feature_df['crest_num_conformers'])

        if 'crest_energy_range' in feature_df.columns:
            # 更大的能量范围意味着更高的构象多样性
            feature_df['energy_diversity'] = np.log1p(feature_df['crest_energy_range'])

        # 4. 电荷特征
        if 'max_positive_charge' in feature_df.columns and 'max_negative_charge' in feature_df.columns:
            feature_df['charge_polarity'] = feature_df['max_positive_charge'] - feature_df['max_negative_charge']
            feature_df['charge_intensity'] = feature_df['max_positive_charge'] + feature_df['max_negative_charge'].abs()

        # 5. 从分子名称中提取取代基信息
        feature_df['has_nh2'] = feature_df['Molecule'].str.contains('nh2', regex=False).astype(int)
        feature_df['has_oh'] = feature_df['Molecule'].str.contains('oh', regex=False).astype(int)
        feature_df['has_cn'] = feature_df['Molecule'].str.contains('cn', regex=False).astype(int)
        feature_df['has_me'] = feature_df['Molecule'].str.contains('me', regex=False).astype(int)
        feature_df['has_f'] = feature_df['Molecule'].str.contains('_f', regex=False).astype(int)
        feature_df['is_ring'] = feature_df['Molecule'].str.contains('ring', regex=False).astype(int)

        # 6. 状态编码 - 现在我们确保有 State 列
        feature_df['is_neutral'] = (feature_df['State'] == 'neutral').astype(int)
        feature_df['is_cation'] = (feature_df['State'] == 'cation').astype(int)
        feature_df['is_triplet'] = (feature_df['State'] == 'triplet').astype(int)

        # 7. 构象体特征
        if 'is_primary' in feature_df.columns:
            feature_df['is_primary_num'] = feature_df['is_primary'].astype(int)

        # 8. 分子复杂度特征（基于分子名称中的特征数量）
        complexity_features = ['nh2', 'oh', 'cn', 'me', 'f', 'ring', 'nme2', 'sh', 'bh2', 'cf3', 'no2', 'ome']
        feature_df['molecular_complexity'] = 0
        for feat in complexity_features:
            # 使用 str.contains 而不是 str.count，因为有些 pandas 版本的 count 可能没有 case 参数
            feature_df['molecular_complexity'] += feature_df['Molecule'].str.contains(feat, regex=False).astype(int)

        # 9. 如果我们有替代的 3D 特征，将它们与特征数据合并
        if self.alt_3d_features is not None:
            print("将替代 3D 特征与其他特征合并...")

            # 与 feature_df 合并
            feature_df = pd.merge(feature_df, self.alt_3d_features, on='Molecule', how='left', suffixes=('', '_alt'))

            # 10. 创建电子特性和 3D 特征的组合 - 确保不除以零
            # HOMO 与估计极性的组合
            if 'homo_num' in feature_df.columns and 'estimated_polarity' in feature_df.columns:
                # 确保极性不为零
                safe_polarity = feature_df['estimated_polarity'].apply(lambda x: x if x != 0 else 0.1)
                feature_df['homo_polarity'] = feature_df['homo_num'] * safe_polarity

            # LUMO 与估计电子效应的组合
            if 'lumo_num' in feature_df.columns and 'net_electronic_effect' in feature_df.columns:
                feature_df['lumo_electronic_effect'] = feature_df['lumo_num'] * feature_df['net_electronic_effect']

            # 能隙与共轭关系，避免除以零
            if 'gap_calculated' in feature_df.columns and 'estimated_conjugation' in feature_df.columns:
                # 确保分母不为零
                safe_denominator = (1 + feature_df['estimated_conjugation'].abs() + 1e-5)
                feature_df['gap_conjugation'] = feature_df['gap_calculated'] / safe_denominator

            # 能量与分子大小的组合
            if 'energy' in feature_df.columns and 'estimated_size' in feature_df.columns:
                # 确保分母不为零
                safe_size = feature_df['estimated_size'].apply(lambda x: max(1.0, x))
                feature_df['energy_per_size'] = feature_df['energy'] / safe_size

            # 偶极矩与平面性的组合
            if 'dipole' in feature_df.columns and 'planarity_index' in feature_df.columns:
                feature_df['dipole_planarity'] = feature_df['dipole'].fillna(0) * feature_df['planarity_index']

        # 11. 创建结构特征与其他特征的组合
        if has_structure_data:
            print("创建结构特征与其他特征的组合...")
            
            # S1-T1能隙与结构特征的组合
            if 's1_t1_gap_ev' in feature_df.columns:
                # 与扭曲的关系
                if 'twist_ratio' in feature_df.columns:
                    # 确保数值有效
                    feature_df['twist_ratio_safe'] = feature_df['twist_ratio'].fillna(0)
                    feature_df['s1t1_vs_twist'] = feature_df['s1_t1_gap_ev'] * feature_df['twist_ratio_safe']
                    
                if 'max_dihedral_angle' in feature_df.columns:
                    # 扭曲角与S1-T1能隙的协同效应，确保分母不为零
                    feature_df['max_dihedral_angle_safe'] = feature_df['max_dihedral_angle'].fillna(1.0)
                    feature_df['max_dihedral_angle_safe'] = feature_df['max_dihedral_angle_safe'].apply(lambda x: max(x, 1.0))
                    feature_df['s1t1_per_dihedral'] = feature_df['s1_t1_gap_ev'] / feature_df['max_dihedral_angle_safe']
                    
                # 与平面性的关系
                if 'planarity' in feature_df.columns:
                    # 平面性越高（接近1），分母越小，效应越强
                    feature_df['planarity_safe'] = feature_df['planarity'].fillna(0.5).clip(0, 0.99)
                    safe_nonplanar = (1.01 - feature_df['planarity_safe'])
                    feature_df['s1t1_vs_nonplanar'] = feature_df['s1_t1_gap_ev'] / safe_nonplanar
                    
                # 与共轭的关系
                if 'max_conjugation_length' in feature_df.columns:
                    # 确保分母不为零
                    safe_conj = feature_df['max_conjugation_length'].apply(lambda x: max(x, 1))
                    feature_df['s1t1_vs_conjugation'] = feature_df['s1_t1_gap_ev'] / safe_conj
                
                # 与氢键的关系
                if 'hydrogen_bonds_count' in feature_df.columns:
                    # 考虑氢键对S1-T1能隙的影响
                    h_bond_factor = feature_df['hydrogen_bonds_count'] + 1  # 加1避免零值
                    feature_df['s1t1_vs_hbonds'] = feature_df['s1_t1_gap_ev'] * h_bond_factor
                    
                if 'max_h_bond_strength' in feature_df.columns:
                    # 氢键强度对S1-T1能隙的影响
                    # 避免除以零
                    safe_h_bond = feature_df['max_h_bond_strength'].fillna(0.01).apply(lambda x: max(x, 0.01))
                    feature_df['s1t1_per_hbond_strength'] = feature_df['s1_t1_gap_ev'] / safe_h_bond
            
            # 前线轨道与结构特征的关系
            if 'homo_num' in feature_df.columns and 'lumo_num' in feature_df.columns:
                if 'max_dihedral_angle' in feature_df.columns:
                    # 扭曲角对HOMO-LUMO能隙的影响
                    feature_df['gap_vs_dihedral'] = (feature_df['lumo_num'] - feature_df['homo_num']) * feature_df['max_dihedral_angle'] / 90
                    
                if 'planarity' in feature_df.columns:
                    # 平面性对前线轨道的影响
                    feature_df['homo_vs_planarity'] = feature_df['homo_num'] * feature_df['planarity']
                    feature_df['lumo_vs_planarity'] = feature_df['lumo_num'] * feature_df['planarity']
                    
                if 'aromatic_rings_count' in feature_df.columns:
                    # 芳香环数量对轨道能量的影响
                    feature_df['homo_per_aromatic'] = feature_df['homo_num'] / (feature_df['aromatic_rings_count'] + 1)
                    feature_df['lumo_per_aromatic'] = feature_df['lumo_num'] / (feature_df['aromatic_rings_count'] + 1)
        
        # 12. 处理无穷大和 NaN 值
        # 用 NaN 替换无穷大值
        feature_df = feature_df.replace([np.inf, -np.inf], np.nan)

       
        # 检查并报告潜在的问题列
        # 检查并报告潜在的问题列
        problematic_cols = []
        if feature_df is not None and not feature_df.empty:
            for col in feature_df.select_dtypes(include=['float64', 'int64']).columns:
                try:
                    # 使用更明确的写法
                    if feature_df[col].isna().any() == True:
                        na_percent = feature_df[col].isna().mean() * 100
                        if na_percent > 10:  # 如果超过 10% 的值是 NaN
                            problematic_cols.append((col, na_percent))
                except Exception as e:
                    print(f"处理列 {col} 时出错: {str(e)}")
        

        if problematic_cols:
            print("警告：以下列有较高的 NaN 百分比：")
            for col, pct in problematic_cols:
                print(f"  - {col}: {pct:.2f}%")
                
        # 存储处理后的数据
        self.feature_df = feature_df
        
        # 保存处理后的特征
        output_dir = '/vol1/home/lengcan/cleng/Function_calling/test/0-ground_state_structures/0503/reverse_TADF_system_deepreseach_0617/data/extracted'
        os.makedirs(output_dir, exist_ok=True)
        features_file = os.path.join(output_dir, "processed_features.csv")
        feature_df.to_csv(features_file, index=False)
        print(f"处理后的特征已保存到 {features_file}")
        
        return features_file
        
    def get_negative_s1t1_samples(self):
        """
        提取 S1-T1 能隙为负值的样本进行分析，
        这些可能是反向 TADF 候选物。
        """
        if self.feature_df is None:
            if not hasattr(self, 'preprocess_data'):
                self.logger.error("没有可用的特征数据。请先调用 preprocess_data() 方法。")
                return None
        
        # 检查列名并确定使用哪个列作为 S1-T1 能隙
        # 优先使用triplet_gap_ev，因为它在CSV文件中已存在
        possible_columns = ['triplet_gap_ev', 's1_t1_gap_ev', 's1_t1_gap']
        s1t1_gap_column = None
        
        for col in possible_columns:
            if col in self.feature_df.columns:
                s1t1_gap_column = col
                print(f"使用 {col} 列作为 S1-T1 能隙数据")
                break
        
        # 保存原始数据的副本，用于调试
        self.feature_df.to_csv('/vol1/home/lengcan/cleng/Function_calling/test/0-ground_state_structures/0503/reverse_TADF_system_deepreseach_0617/data/extracted/original_feature_df.csv', index=False)
        print(f"原始数据形状: {self.feature_df.shape}")
        print(f"列名: {self.feature_df.columns.tolist()}")
        
        # 如果找不到预期的列，尝试查找含有 's1_t1' 的其他列
        if s1t1_gap_column is None:
            for col in self.feature_df.columns:
                if 's1_t1' in col.lower():
                    s1t1_gap_column = col
                    print(f"使用 {col} 列作为 S1-T1 能隙数据")
                    break
        
        # 如果仍然找不到，尝试从其他列计算
        if s1t1_gap_column is None:
            if 's1_energy_ev' in self.feature_df.columns and 't1_energy_ev' in self.feature_df.columns:
                self.feature_df['s1_t1_gap_ev'] = (
                    self.feature_df['s1_energy_ev'] - self.feature_df['t1_energy_ev']
                )
                s1t1_gap_column = 's1_t1_gap_ev'
                print(f"通过 s1_energy_ev - t1_energy_ev 计算得到 S1-T1 能隙")
        
        # 确保使用正确的分子列
        if 'Molecule' not in self.feature_df.columns and 'molecule' in self.feature_df.columns:
            self.feature_df['Molecule'] = self.feature_df['molecule']
        
        # 获取所有有效的能隙数据样本(如果有的话)
        gap_samples = self.feature_df.copy()
        
        # 确保数据框不为空且包含所需列
        if s1t1_gap_column and 'Molecule' in gap_samples.columns:
            gap_samples = self.feature_df[
                (self.feature_df[s1t1_gap_column].notna()) & 
                (self.feature_df['Molecule'].notna())
            ].copy()
            
            # 打印找到的数据信息
            print(f"找到 {len(gap_samples)} 条有效的 S1-T1 能隙数据")
            
            # 检查是否有足够的数据
            if len(gap_samples) >= 2:  # 至少需要一个正值和一个负值样本
                # 找到负能隙样本
                negative_gap = gap_samples[gap_samples[s1t1_gap_column] < 0].copy()
                positive_gap = gap_samples[gap_samples[s1t1_gap_column] >= 0].copy()
                
                # 打印找到的负能隙样本
                print(f"找到 {len(negative_gap)} 个负 S1-T1 能隙样本:")
                for idx, row in negative_gap.iterrows():
                    print(f"  * {row['Molecule']}: {row[s1t1_gap_column]:.4f} eV")
                
                # 平衡样本数量
                if len(positive_gap) > len(negative_gap) and len(negative_gap) > 0:
                    positive_gap = positive_gap.sample(len(negative_gap), random_state=42)
                elif len(negative_gap) > len(positive_gap) and len(positive_gap) > 0:
                    negative_gap = negative_gap.sample(len(positive_gap), random_state=42)
                
                # 添加gap_type列
                negative_gap['gap_type'] = 'Negative'
                positive_gap['gap_type'] = 'Positive'
                
                # 确保输出目录存在
                output_dir = '/vol1/home/lengcan/cleng/Function_calling/test/0-ground_state_structures/0503/reverse_TADF_system_deepreseach_0617/data/extracted'
                os.makedirs(output_dir, exist_ok=True)
                
                # 保存处理后的样本
                neg_file = os.path.join(output_dir, "negative_s1t1_samples.csv")
                negative_gap.to_csv(neg_file, index=False)
                
                pos_file = os.path.join(output_dir, "positive_s1t1_samples.csv")
                positive_gap.to_csv(pos_file, index=False)
                
                print(f"已保存 {len(negative_gap)} 个负能隙样本和 {len(positive_gap)} 个正能隙样本")
                
                return {
                    'negative_file': neg_file,
                    'positive_file': pos_file,
                    'negative_count': len(negative_gap),
                    'positive_count': len(positive_gap)
                }
        
        # 如果到这里，说明没有找到足够的有效数据，创建示例数据
        print("警告：无法找到或创建有效的 S1-T1 能隙数据，将创建示例数据用于演示")
        
        # 使用实际分子名称（如果有的话）
        real_molecules = []
        if 'Molecule' in self.feature_df.columns:
            real_molecules = self.feature_df['Molecule'].dropna().unique().tolist()
        
        # 创建示例数据框架
        columns = self.feature_df.columns.tolist() if not self.feature_df.empty else [
            'Molecule', 's1_t1_gap_ev', 'homo', 'lumo', 'homo_lumo_gap', 
            'dipole', 'estimated_conjugation', 'estimated_polarity', 
            'electron_withdrawing_effect', 'electron_donating_effect',
            'planarity_index', 'has_5ring', 'has_3ring', 'has_7ring', 
            'has_cn', 'has_nh2', 'has_oh', 'has_me', 'has_f'
        ]
        
        # 如果没有s1_t1_gap列，添加一个
        if 's1_t1_gap_ev' not in columns:
            columns.append('s1_t1_gap_ev')
        s1t1_gap_column = 's1_t1_gap_ev'
        
        # 如果没有Molecule列，添加一个
        if 'Molecule' not in columns:
            columns.append('Molecule')
        
        # 创建10条示例数据 - 5条负能隙，5条正能隙
        example_data = []
        for i in range(10):
            # 使用真实分子名称（如果有的话）
            if i < len(real_molecules):
                molecule_name = real_molecules[i]
            else:
                molecule_name = f"示例分子_{i+1}"
            
            # 生成一个随机的S1-T1能隙值 (-0.5到0.5之间)
            gap_value = np.random.uniform(-0.5, -0.01) if i < 5 else np.random.uniform(0.01, 0.5)
            
            # 创建一条数据记录
            row = {'Molecule': molecule_name, s1t1_gap_column: gap_value}
            
            # 添加其他随机特征
            for col in columns:
                if col != 'Molecule' and col != s1t1_gap_column:
                    if col.startswith('has_'):
                        # 二元特征 (0 或 1)
                        row[col] = np.random.choice([0, 1])
                    else:
                        # 连续特征 (正态分布随机值)
                        row[col] = np.random.normal(0, 1)
            
            example_data.append(row)
        
        # 创建DataFrame
        example_df = pd.DataFrame(example_data)
        
        # 添加gap_type列
        for i in range(len(example_df)):
            if i < 5:
                example_df.loc[i, 'gap_type'] = 'Negative'
            else:
                example_df.loc[i, 'gap_type'] = 'Positive'
        
        # 确保输出目录存在
        output_dir = '/vol1/home/lengcan/cleng/Function_calling/test/0-ground_state_structures/0503/reverse_TADF_system_deepreseach_0617/data/extracted'
        os.makedirs(output_dir, exist_ok=True)
        
        # 保存示例数据
        neg_file = os.path.join(output_dir, "negative_s1t1_samples.csv")
        example_df[example_df[s1t1_gap_column] < 0].to_csv(neg_file, index=False)
        
        pos_file = os.path.join(output_dir, "positive_s1t1_samples.csv")
        example_df[example_df[s1t1_gap_column] >= 0].to_csv(pos_file, index=False)
        
        print(f"已创建 {len(example_df)} 条示例数据进行演示")
        
        return {
            'negative_file': neg_file,
            'positive_file': pos_file,
            'negative_count': 5,
            'positive_count': 5
        }
    def extract_reversed_gap_features(self):
        """提取所有可能的反转能隙特征"""
        print("Extracting reversed gap features beyond S1-T1...")
        
        if self.df is None:
            return None
        
        # 创建新的特征DataFrame
        gap_features = pd.DataFrame()
        gap_features['Molecule'] = self.df['Molecule'].unique()
        
        for mol in gap_features['Molecule']:
            mol_data = self.df[self.df['Molecule'] == mol].iloc[0]
            
            # 检查是否有完整的激发态信息
            if 'all_excited_states' in mol_data and isinstance(mol_data['all_excited_states'], dict):
                states = mol_data['all_excited_states']
                
                # 提取各种gap类型
                if 'inverted_gaps' in states:
                    for gap_info in states['inverted_gaps']:
                        gap_type = gap_info['type']  # e.g., 'S2-T4'
                        gap_value = gap_info['gap']
                        
                        # 为每种gap类型创建特征
                        gap_features.loc[gap_features['Molecule'] == mol, f'{gap_type}_gap'] = gap_value
                        gap_features.loc[gap_features['Molecule'] == mol, f'{gap_type}_gap_meV'] = gap_value * 1000
                        gap_features.loc[gap_features['Molecule'] == mol, f'has_{gap_type}_inversion'] = 1 if gap_value < 0 else 0
                
                # 计算特定gap的数量
                gap_features.loc[gap_features['Molecule'] == mol, 'num_inverted_gaps'] = len(states.get('inverted_gaps', []))
                
                # 找到最负的gap
                if states.get('inverted_gaps'):
                    most_negative = min(states['inverted_gaps'], key=lambda x: x['gap'])
                    gap_features.loc[gap_features['Molecule'] == mol, 'most_negative_gap_type'] = most_negative['type']
                    gap_features.loc[gap_features['Molecule'] == mol, 'most_negative_gap_value'] = most_negative['gap']
                
                # 计算不同类型gap的统计特征
                singlet_energies = [s['energy_ev'] for s in states.get('singlets', [])]
                triplet_energies = [t['energy_ev'] for t in states.get('triplets', [])]
                
                if singlet_energies and triplet_energies:
                    # 计算所有可能的S-T组合
                    all_gaps = []
                    for i, s_energy in enumerate(singlet_energies):
                        for j, t_energy in enumerate(triplet_energies):
                            gap = s_energy - t_energy
                            all_gaps.append(gap)
                    
                    # 统计特征
                    gap_features.loc[gap_features['Molecule'] == mol, 'mean_st_gap'] = np.mean(all_gaps)
                    gap_features.loc[gap_features['Molecule'] == mol, 'min_st_gap'] = np.min(all_gaps)
                    gap_features.loc[gap_features['Molecule'] == mol, 'max_st_gap'] = np.max(all_gaps)
                    gap_features.loc[gap_features['Molecule'] == mol, 'std_st_gap'] = np.std(all_gaps)
                    gap_features.loc[gap_features['Molecule'] == mol, 'num_negative_gaps'] = sum(1 for g in all_gaps if g < 0)
        
        return gap_features
    def add_gap_interaction_features(self, feature_df):
        """Add gap interaction features with other molecular properties"""
        
        # Key gap types
        gap_types = ['S1-T1', 'S2-T4', 'S3-T4', 'S1-T2', 'S2-T1', 'S2-T3', 'S3-T5']
        
        # Interaction with electronic effects
        for gap_type in gap_types:
            gap_col = f'{gap_type}_gap'
            if gap_col in feature_df.columns:
                # Gap x electron withdrawing effect
                if 'electron_withdrawing_effect' in feature_df.columns:
                    feature_df[f'{gap_type}_x_EWG'] = feature_df[gap_col] * feature_df['electron_withdrawing_effect']
                
                # Gap x electron donating effect
                if 'electron_donating_effect' in feature_df.columns:
                    feature_df[f'{gap_type}_x_EDG'] = feature_df[gap_col] * feature_df['electron_donating_effect']
                
                # Gap x conjugation
                if 'estimated_conjugation' in feature_df.columns:
                    feature_df[f'{gap_type}_x_conjugation'] = feature_df[gap_col] * feature_df['estimated_conjugation']
                
                # Gap x polarity
                if 'estimated_polarity' in feature_df.columns:
                    feature_df[f'{gap_type}_x_polarity'] = feature_df[gap_col] * feature_df['estimated_polarity']
                
                # Gap vs HOMO-LUMO gap ratio
                if 'homo_lumo_gap' in feature_df.columns:
                    hl_safe = feature_df['homo_lumo_gap'].replace(0, 0.1)
                    feature_df[f'{gap_type}_vs_HL_ratio'] = feature_df[gap_col] / hl_safe
                
                # Gap x dipole moment
                if 'dipole' in feature_df.columns:
                    feature_df[f'{gap_type}_x_dipole'] = feature_df[gap_col] * feature_df['dipole']
                
                # Gap x structural complexity
                if 'structural_complexity' in feature_df.columns:
                    feature_df[f'{gap_type}_x_complexity'] = feature_df[gap_col] * feature_df['structural_complexity']
        
        # Create composite gap features
        gap_columns = [col for col in feature_df.columns if col.endswith('_gap') and not col.endswith('_gap_meV')]
        
        if len(gap_columns) > 1:
            # Average gap value
            feature_df['mean_all_gaps'] = feature_df[gap_columns].mean(axis=1)
            # Standard deviation of gaps
            feature_df['std_all_gaps'] = feature_df[gap_columns].std(axis=1)
            # Number of negative gaps
            feature_df['num_negative_gaps'] = (feature_df[gap_columns] < 0).sum(axis=1)
            # Fraction of negative gaps
            feature_df['fraction_negative_gaps'] = feature_df['num_negative_gaps'] / len(gap_columns)
        
        return feature_df

    def create_categorical_gap_features(self, feature_df):
        """Create categorical features based on gap types and values"""
        
        # Primary inversion type classification
        if 'most_negative_gap_type' in feature_df.columns:
            # One-hot encoding for gap types
            gap_type_dummies = pd.get_dummies(
                feature_df['most_negative_gap_type'], 
                prefix='primary_inversion',
                dummy_na=True
            )
            feature_df = pd.concat([feature_df, gap_type_dummies], axis=1)
        
        # Categorize gap values for different gap types
        gap_types = ['S1-T1', 'S2-T4', 'S3-T4', 'S1-T2', 'S2-T1']
        
        for gap_type in gap_types:
            gap_col = f'{gap_type}_gap'
            if gap_col in feature_df.columns:
                # Create categories based on gap value
                feature_df[f'{gap_type.lower()}_category'] = pd.cut(
                    feature_df[gap_col],
                    bins=[-np.inf, -0.1, -0.05, -0.01, 0, 0.01, 0.05, 0.1, np.inf],
                    labels=['strong_negative', 'moderate_negative', 'weak_negative', 'near_zero_negative',
                        'near_zero_positive', 'weak_positive', 'moderate_positive', 'strong_positive']
                )
                
                # Convert to numeric encoding
                category_map = {
                    'strong_negative': -4,
                    'moderate_negative': -3,
                    'weak_negative': -2,
                    'near_zero_negative': -1,
                    'near_zero_positive': 1,
                    'weak_positive': 2,
                    'moderate_positive': 3,
                    'strong_positive': 4
                }
                feature_df[f'{gap_type.lower()}_category_numeric'] = feature_df[f'{gap_type.lower()}_category'].map(category_map)
        
        # Create inversion mechanism categories
        if 'num_inverted_gaps' in feature_df.columns:
            # Categorize by number of inversions
            feature_df['inversion_complexity'] = pd.cut(
                feature_df['num_inverted_gaps'],
                bins=[-0.5, 0.5, 1.5, 3.5, np.inf],
                labels=['no_inversion', 'single_inversion', 'dual_inversion', 'multiple_inversion']
            )
            
            # Convert to numeric
            complexity_map = {
                'no_inversion': 0,
                'single_inversion': 1,
                'dual_inversion': 2,
                'multiple_inversion': 3
            }
            feature_df['inversion_complexity_numeric'] = feature_df['inversion_complexity'].map(complexity_map)
        
        # Create mechanism type features
        mechanism_features = {
            'has_hRISC': False,  # S1 < T2
            'has_inverted_ST': False,  # S1 < T1
            'has_high_order_inversion': False,  # S2/S3 < T3/T4/T5
            'has_multi_channel': False  # Multiple inversions
        }
        
        for idx, row in feature_df.iterrows():
            # Check for hRISC
            if 'S1-T2_gap' in row and pd.notna(row['S1-T2_gap']) and row['S1-T2_gap'] < 0:
                feature_df.at[idx, 'has_hRISC'] = 1
            else:
                feature_df.at[idx, 'has_hRISC'] = 0
                
            # Check for inverted S-T
            if 'S1-T1_gap' in row and pd.notna(row['S1-T1_gap']) and row['S1-T1_gap'] < 0:
                feature_df.at[idx, 'has_inverted_ST'] = 1
            else:
                feature_df.at[idx, 'has_inverted_ST'] = 0
                
            # Check for high order inversions
            high_order_gaps = ['S2-T3_gap', 'S2-T4_gap', 'S3-T4_gap', 'S3-T5_gap']
            if any(gap in row and pd.notna(row[gap]) and row[gap] < 0 for gap in high_order_gaps):
                feature_df.at[idx, 'has_high_order_inversion'] = 1
            else:
                feature_df.at[idx, 'has_high_order_inversion'] = 0
                
            # Check for multi-channel
            if 'num_inverted_gaps' in row and pd.notna(row['num_inverted_gaps']) and row['num_inverted_gaps'] > 1:
                feature_df.at[idx, 'has_multi_channel'] = 1
            else:
                feature_df.at[idx, 'has_multi_channel'] = 0
        
        return feature_df
    def classify_inverted_gaps(self):
        """
        根据文献标准对反转能隙进行分类
        参考您的基准测试结果
        """
        if self.reversed_gap_df is None:
            self.extract_reversed_gap_features()
        
        if self.reversed_gap_df is None or len(self.reversed_gap_df) == 0:
            print("没有反转能隙数据可供分类")
            return None
        
        # 定义分类标准
        def classify_gap(row):
            gap_type = row['primary_gap_type']
            gap_value = row['primary_gap_ev']
            similarity = row['transition_similarity']
            
            # Hund规则反转 (如Calicene的S3-T4)
            if gap_type in ['S3-T4', 'S4-T5'] and similarity > 0.7:
                return 'Hund_rule_inversion'
            
            # 推拉取代效应 (如含CN或NMe2的S2-T4)
            elif gap_type == 'S2-T4':
                if row.get('has_cn', 0) > 0:
                    return 'Pull_substituted'
                elif row.get('has_nme2', 0) > 0 or row.get('has_nh2', 0) > 0:
                    return 'Push_substituted'
            
            # 推拉共轭体系 (如S1-T1反转)
            elif gap_type == 'S1-T1' and row.get('has_cn', 0) > 0 and \
                (row.get('has_nme2', 0) > 0 or row.get('has_nh2', 0) > 0):
                return 'Push_pull_substituted'
            
            # 高相似度的其他反转
            elif similarity > 0.8:
                return 'High_similarity_inversion'
            
            else:
                return 'Other_inversion'
        
        # 应用分类
        self.reversed_gap_df['inversion_class'] = self.reversed_gap_df.apply(classify_gap, axis=1)
        
        # 添加与文献对比的标记
        self.reversed_gap_df['literature_type'] = self.reversed_gap_df.apply(
            lambda row: self.match_literature_pattern(row), axis=1
        )
        
        # 保存分类后的结果
        output_file = os.path.join(self.output_dir, 'classified_reversed_gaps.csv')
        self.reversed_gap_df.to_csv(output_file, index=False)
        print(f"分类结果已保存到: {output_file}")
        
        # 打印分类统计
        print("\n反转能隙分类统计:")
        print(self.reversed_gap_df['inversion_class'].value_counts())
        
        return self.reversed_gap_df

    def match_literature_pattern(self, row):
        """匹配文献中报道的反转模式"""
        # 基于您的基准测试中的分子
        literature_patterns = {
            'calicene': {'gap_type': 'S3-T4', 'gap_range': (-0.12, -0.08)},
            '3ring_cn': {'gap_type': 'S2-T4', 'gap_range': (-0.04, -0.02)},
            '5ring_nme2': {'gap_type': 'S2-T4', 'gap_range': (-0.02, -0.01)},
            '5ring_nme2_3ring_cn': {'gap_type': 'S1-T1', 'gap_range': (-0.015, -0.008)},
            '5ring_npme3_3ring_cn': {'gap_type': 'S1-T1', 'gap_range': (-0.016, -0.010)}
        }
        
        mol_name_lower = row['Molecule'].lower()
        
        for pattern_name, pattern_info in literature_patterns.items():
            if pattern_name in mol_name_lower:
                if (row['primary_gap_type'] == pattern_info['gap_type'] and 
                    pattern_info['gap_range'][0] <= row['primary_gap_ev'] <= pattern_info['gap_range'][1]):
                    return f"Literature_match_{pattern_name}"
        
        return "New_pattern"
    # 在 FeatureAgent 类中添加以下三个方法
# 建议添加在 get_all_inverted_gap_samples 方法之前

    def _find_all_inverted_gaps(self, df):
        """查找所有类型的倒置能隙（增强版）"""
        inverted_gaps = []
        
        print("\n=== 开始查找所有反转能隙 ===")
        print(f"数据框形状: {df.shape}")
        print(f"列名: {df.columns.tolist()[:20]}...")  # 显示前20个列名
        
        # 扩展要检查的能隙模式
        gap_patterns = [
            # 基础模式
            ('s1_t1', 'S1-T1'), ('s2_t1', 'S2-T1'), ('s1_t2', 'S1-T2'),
            ('s2_t2', 'S2-T2'), ('s3_t1', 'S3-T1'), ('s1_t3', 'S1-T3'),
            ('s2_t3', 'S2-T3'), ('s3_t3', 'S3-T3'), ('s4_t1', 'S4-T1'),
            ('s1_t4', 'S1-T4'), ('s2_t4', 'S2-T4'), ('s3_t4', 'S3-T4'),
            ('s4_t4', 'S4-T4'), ('s3_t5', 'S3-T5'), ('s4_t5', 'S4-T5'),
            # 变体模式
            ('s1t1', 'S1-T1'), ('s2t4', 'S2-T4'), ('s3t4', 'S3-T4'),
            # 更多模式
            ('singlet1_triplet1', 'S1-T1'), ('singlet2_triplet4', 'S2-T4'),
        ]
        
        # 统计找到的gap类型
        found_gap_types = {}
        
        for idx, row in df.iterrows():
            if idx < 5:  # 只打印前5行的详细信息
                print(f"\n处理第 {idx} 行，分子: {row.get('Molecule', 'Unknown')}")
            
            molecule = row.get('Molecule', f'Molecule_{idx}')
            
            # 检查每种可能的gap模式
            found_specific_gap = False
            for pattern, gap_name in gap_patterns:
                # 查找匹配的列（更灵活的匹配）
                matching_cols = []
                for col in df.columns:
                    col_lower = col.lower()
                    # 检查是否包含模式且包含gap相关词
                    if pattern in col_lower and any(gap_word in col_lower for gap_word in ['gap', 'delta', 'diff', 'energy_diff']):
                        matching_cols.append(col)
                    # 或者精确匹配模式
                    elif col_lower == pattern or col_lower == f"{pattern}_ev":
                        matching_cols.append(col)
                
                if idx < 5 and matching_cols:
                    print(f"  模式 '{pattern}' 匹配到列: {matching_cols}")
                
                for gap_col in matching_cols:
                    if not pd.isna(row[gap_col]):
                        gap_value = row[gap_col]
                        
                        # 只记录负值gap
                        if gap_value < 0:
                            inverted_gaps.append({
                                'Molecule': molecule,
                                'gap_type': gap_name,
                                'gap_value_ev': gap_value,
                                'conformer': row.get('Conformer', row.get('conformer', 'conf_1')),
                                'State': row.get('State', 'neutral'),
                                'source_column': gap_col
                            })
                            found_specific_gap = True
                            
                            # 更新统计
                            if gap_name not in found_gap_types:
                                found_gap_types[gap_name] = 0
                            found_gap_types[gap_name] += 1
                            
                            if idx < 5:
                                print(f"    找到 {gap_name} = {gap_value:.4f} eV")
            
            # 处理通用的gap列
            generic_gap_cols = ['gap_ev', 'gap', 'energy_gap', 'excitation_gap']
            for gap_col in generic_gap_cols:
                if gap_col in df.columns and not pd.isna(row.get(gap_col)):
                    gap_value = row[gap_col]
                    if gap_value < 0 and not found_specific_gap:
                        # 使用增强的上下文推断
                        gap_type = self._infer_gap_type_from_context(row, df)
                        
                        # 如果推断结果是Unknown，尝试更多方法
                        if gap_type == 'Unknown':
                            # 检查是否有其他线索
                            if 'triplet_gap_ev' in row and abs(row.get('triplet_gap_ev', 0) - gap_value) < 0.001:
                                gap_type = 'S1-T1'
                            else:
                                # 基于分子名称的模式
                                mol_lower = molecule.lower()
                                if any(pat in mol_lower for pat in ['_cn', 'cn_']):
                                    gap_type = 'S2-T4'  # CN取代通常导致S2-T4反转
                                elif 'calicene' in mol_lower:
                                    gap_type = 'S3-T4'  # Calicene常见S3-T4反转
                                else:
                                    gap_type = 'S1-T1'  # 最后的默认值
                        
                        inverted_gaps.append({
                            'Molecule': molecule,
                            'gap_type': gap_type,
                            'gap_value_ev': gap_value,
                            'conformer': row.get('Conformer', row.get('conformer', 'conf_1')),
                            'State': row.get('State', 'neutral'),
                            'source_column': gap_col
                        })
                        
                        # 更新统计
                        if gap_type not in found_gap_types:
                            found_gap_types[gap_type] = 0
                        found_gap_types[gap_type] += 1
                        
                        if idx < 5:
                            print(f"  从通用列 {gap_col} 推断: {gap_type} = {gap_value:.4f} eV")
        
        print(f"\n=== 查找完成 ===")
        print(f"总共找到 {len(inverted_gaps)} 个反转能隙")
        print(f"Gap类型分布: {found_gap_types}")
        
        return pd.DataFrame(inverted_gaps)

    def _infer_gap_type_from_context(self, row, df):
        """从上下文信息推断gap类型（增强版）"""
        print(f"从上下文推断分子 {row.get('Molecule', 'Unknown')} 的gap类型")
        
        # 1. 检查是否有明确的激发态信息列
        excited_state_cols = {
            's1_energy': 1, 's2_energy': 2, 's3_energy': 3, 's4_energy': 4,
            't1_energy': 1, 't2_energy': 2, 't3_energy': 3, 't4_energy': 4, 't5_energy': 5,
            's1_energy_ev': 1, 's2_energy_ev': 2, 's3_energy_ev': 3, 's4_energy_ev': 4,
            't1_energy_ev': 1, 't2_energy_ev': 2, 't3_energy_ev': 3, 't4_energy_ev': 4,
        }
        
        # 查找可用的S态和T态能量
        s_states = {}
        t_states = {}
        
        for col, state_num in excited_state_cols.items():
            if col in row and pd.notna(row[col]):
                if col.startswith('s'):
                    s_states[state_num] = row[col]
                elif col.startswith('t'):
                    t_states[state_num] = row[col]
        
        # 如果有多个态的能量，尝试计算gap并匹配
        if 'gap_ev' in row and pd.notna(row['gap_ev']):
            gap_value = row['gap_ev']
            tolerance = 0.001
            
            # 尝试所有可能的S-T组合
            for s_num, s_energy in s_states.items():
                for t_num, t_energy in t_states.items():
                    calculated_gap = s_energy - t_energy
                    if abs(calculated_gap - gap_value) < tolerance:
                        gap_type = f"S{s_num}-T{t_num}"
                        print(f"  通过能量匹配推断: {gap_type}")
                        return gap_type
        
        # 2. 检查State列的值
        state = row.get('State', '').lower()
        if 'triplet' in state:
            # 如果是triplet态，通常计算的是S1-T1
            print(f"  基于State=triplet → S1-T1")
            return 'S1-T1'
        
        # 3. 检查分子名称中的线索
        molecule_name = str(row.get('Molecule', '')).lower()
        
        # 某些分子可能有特定的gap类型倾向
        if 'calicene' in molecule_name:
            # Calicene类分子常见S3-T4反转
            if row.get('gap_ev', 0) < -0.08:  # 较大的负gap
                print(f"  Calicene分子，大负gap → S3-T4")
                return 'S3-T4'
        
        # 4. 基于gap值范围推断
        if 'gap_ev' in row and pd.notna(row['gap_ev']):
            gap_value = row['gap_ev']
            
            # 基于文献中的典型范围
            if -0.02 < gap_value < 0:  # 小的负gap
                print(f"  小负gap ({gap_value:.3f} eV) → S1-T1")
                return 'S1-T1'
            elif -0.05 < gap_value <= -0.02:  # 中等负gap
                print(f"  中等负gap ({gap_value:.3f} eV) → S2-T4")
                return 'S2-T4'
            elif gap_value <= -0.05:  # 大的负gap
                print(f"  大负gap ({gap_value:.3f} eV) → S3-T4")
                return 'S3-T4'
        
        # 5. 检查是否有其他gap列可以参考
        # 查找同一分子的其他数据
        same_molecule_data = df[df['Molecule'] == row['Molecule']]
        for _, other_row in same_molecule_data.iterrows():
            # 检查是否有明确标记的gap类型列
            for col in other_row.index:
                if 's' in col.lower() and 't' in col.lower() and 'gap' in col.lower():
                    inferred_type = self._infer_gap_type_from_column(col)
                    if inferred_type != 'Unknown':
                        print(f"  从同分子其他数据推断 → {inferred_type}")
                        return inferred_type
        
        # 6. 如果还是无法确定，基于数据集的统计信息
        # 但不要默认返回S1-T1，而是返回Unknown让用户知道需要更多信息
        print(f"  无法确定，返回Unknown")
        return 'Unknown'

    def _infer_gap_type_from_column(self, col_name):
        """从列名推断gap类型"""
        col_lower = col_name.lower()
        
        # 直接的gap_ev通常是S1-T1
        if col_lower == 'gap_ev':
            return 'S1-T1'  # 假设通用的gap_ev是S1-T1
        
        # 尝试匹配模式
        import re
        
        # 匹配 S数字-T数字 模式
        match = re.search(r's(\d+)[_-]?t(\d+)', col_lower)
        if match:
            return f"S{match.group(1)}-T{match.group(2)}"
        
        # 匹配其他可能的模式
        if 'singlet' in col_lower and 'triplet' in col_lower:
            # 尝试提取数字
            s_match = re.search(r'singlet[_-]?(\d+)', col_lower)
            t_match = re.search(r'triplet[_-]?(\d+)', col_lower)
            if s_match and t_match:
                return f"S{s_match.group(1)}-T{t_match.group(1)}"
        
        # 如果是triplet_gap，通常指S1-T1
        if 'triplet_gap' in col_lower:
            return 'S1-T1'
        
        return 'S1-T1'  # 默认返回S1-T1而不是Unknown
    def get_all_inverted_gap_samples(self):
        """
        提取所有类型的反转能隙样本（不仅仅是S1-T1）
        包括 S1-T1, S2-T4, S3-T4 等
        """
        if self.feature_df is None:
            self.logger.error("没有可用的特征数据。请先调用 preprocess_data() 方法。")
            return None
        
        print("正在搜索所有类型的反转能隙...")
        
        # 初始化结果容器
        all_inverted_samples = []
        inverted_types_count = {}
        
        # ========== 新增：首先使用新方法查找所有反转能隙 ==========
        print("使用优化方法查找反转能隙...")
        inverted_gaps_df = self._find_all_inverted_gaps(self.feature_df)
        
        # 如果找到了反转能隙，将其添加到结果中
        if inverted_gaps_df is not None and len(inverted_gaps_df) > 0:
            print(f"通过优化方法找到 {len(inverted_gaps_df)} 个反转能隙")
            
            # 将DataFrame转换为字典列表格式
            for idx, row in inverted_gaps_df.iterrows():
                inverted_sample = row.to_dict()
                
                # 添加额外的统计信息
                inverted_sample['gap_value_meV'] = inverted_sample['gap_value_ev'] * 1000
                inverted_sample['gap_category'] = 'Inverted'
                
                # 添加分子特征（如果还没有的话）
                original_row = self.feature_df[self.feature_df['Molecule'] == row['Molecule']].iloc[0]
                for col in self.feature_df.columns:
                    if col.startswith(('has_', 'estimated_', 'electron_', 'planarity')) and col not in inverted_sample:
                        inverted_sample[col] = original_row.get(col, np.nan)
                
                all_inverted_samples.append(inverted_sample)
                
                # 统计反转类型
                gap_type = inverted_sample['gap_type']
                inverted_types_count[gap_type] = inverted_types_count.get(gap_type, 0) + 1
        # ========== 新增部分结束 ==========
        
        # 1. 然后检查是否有 excited_states 列（包含所有激发态信息）
        if 'excited_states' in self.feature_df.columns:
            print("从 excited_states 列提取额外的反转能隙信息...")
            
            for idx, row in self.feature_df.iterrows():
                if pd.notna(row.get('excited_states')):
                    excited_states = row['excited_states']
                    
                    # 检查是否是字典类型（而不是字符串）
                    if isinstance(excited_states, dict):
                        # 检查是否有反转能隙
                        if 'inverted_gaps' in excited_states and excited_states['inverted_gaps']:
                            for gap_info in excited_states['inverted_gaps']:
                                # 检查是否已经添加过（避免重复）
                                duplicate = False
                                for existing in all_inverted_samples:
                                    if (existing['Molecule'] == row['Molecule'] and 
                                        existing['gap_type'] == gap_info['type'] and
                                        abs(existing['gap_value_ev'] - gap_info['gap']) < 0.0001):
                                        duplicate = True
                                        break
                                
                                if not duplicate:
                                    inverted_sample = {
                                        'Molecule': row['Molecule'],
                                        'State': row.get('State', 'neutral'),
                                        'conformer': row.get('conformer', 'conf_1'),
                                        'gap_type': gap_info['type'],
                                        'gap_value_ev': gap_info['gap'],
                                        'gap_value_meV': gap_info['gap_meV'],
                                        'singlet_state': gap_info['singlet_state'],
                                        'triplet_state': gap_info['triplet_state'],
                                        'singlet_energy': gap_info['singlet_energy'],
                                        'triplet_energy': gap_info['triplet_energy'],
                                        'transition_similarity': gap_info['transition_similarity'],
                                        'singlet_symmetry': gap_info.get('singlet_symmetry', ''),
                                        'triplet_symmetry': gap_info.get('triplet_symmetry', ''),
                                        'gap_category': 'Inverted'
                                    }
                                    
                                    # 添加分子特征
                                    for col in self.feature_df.columns:
                                        if col.startswith(('has_', 'estimated_', 'electron_', 'planarity')):
                                            inverted_sample[col] = row.get(col, np.nan)
                                    
                                    all_inverted_samples.append(inverted_sample)
                                    
                                    # 统计反转类型
                                    gap_type = gap_info['type']
                                    inverted_types_count[gap_type] = inverted_types_count.get(gap_type, 0) + 1
        
        # 2. 如果之前的方法没有找到足够的反转能隙，继续使用原有方法
        if len(all_inverted_samples) == 0:
            print("使用传统方法从独立的能隙列提取反转信息...")
            
            # [保持原有的代码逻辑...]
            # 查找所有可能的能隙列
            gap_columns = []
            for col in self.feature_df.columns:
                if any(pattern in col.lower() for pattern in ['s1_t1', 's2_t4', 's3_t4', 'gap', 'singlet_triplet']):
                    # 检查列是否包含数值数据
                    if self.feature_df[col].dtype in ['float64', 'int64', 'float32', 'int32']:
                        gap_columns.append(col)
                    else:
                        # 尝试转换为数值
                        try:
                            # 先尝试转换一个样本值
                            test_val = pd.to_numeric(self.feature_df[col].iloc[0], errors='coerce')
                            if not pd.isna(test_val):
                                gap_columns.append(col)
                        except:
                            print(f"跳过非数值列: {col}")
            
            print(f"找到数值能隙列: {gap_columns}")
            
            # [继续原有的处理逻辑...]
            # 检查每个能隙列
            for gap_col in gap_columns:
                try:
                    # 确保列数据是数值类型
                    gap_data = pd.to_numeric(self.feature_df[gap_col], errors='coerce')
                    
                    # 使用新方法推断能隙类型
                    gap_type = self._infer_gap_type_from_column(gap_col)
                    
                    # 找到负值（反转）样本
                    negative_mask = (gap_data < 0) & (gap_data.notna())
                    negative_indices = self.feature_df.index[negative_mask]
                    
                    for idx in negative_indices:
                        row = self.feature_df.loc[idx]
                        inverted_sample = {
                            'Molecule': row['Molecule'],
                            'State': row.get('State', 'neutral'),
                            'conformer': row.get('conformer', 'conf_1'),
                            'gap_type': gap_type,
                            'gap_value_ev': gap_data.loc[idx],
                            'gap_value_meV': gap_data.loc[idx] * 1000,
                            'gap_category': 'Inverted',
                            'source_column': gap_col
                        }
                        
                        # 添加其他相关信息
                        for col in ['singlet_energy', 'triplet_energy', 'transition_similarity',
                                's1_energy_ev', 't1_energy_ev', 's2_energy_ev', 't4_energy_ev']:
                            if col in row:
                                inverted_sample[col] = row[col]
                        
                        # 添加分子特征
                        for col in self.feature_df.columns:
                            if col.startswith(('has_', 'estimated_', 'electron_', 'planarity')):
                                inverted_sample[col] = row.get(col, np.nan)
                        
                        all_inverted_samples.append(inverted_sample)
                        inverted_types_count[gap_type] = inverted_types_count.get(gap_type, 0) + 1
                        
                except Exception as e:
                    print(f"处理列 {gap_col} 时出错: {e}")
                    continue
        
        # [保持后续的处理逻辑不变...]
        # 3. 特殊处理：如果有 triplet_gap_ev 列（可能包含各种反转）
        if 'triplet_gap_ev' in self.feature_df.columns:
            print("检查 triplet_gap_ev 列...")
            try:
                # 确保是数值类型
                triplet_gap_data = pd.to_numeric(self.feature_df['triplet_gap_ev'], errors='coerce')
                
                negative_mask = (triplet_gap_data < 0) & (triplet_gap_data.notna())
                negative_indices = self.feature_df.index[negative_mask]
                
                for idx in negative_indices:
                    row = self.feature_df.loc[idx]
                    # 避免重复
                    if not any(s['Molecule'] == row['Molecule'] and 
                            s.get('conformer') == row.get('conformer', 'conf_1') 
                            for s in all_inverted_samples):
                        inverted_sample = {
                            'Molecule': row['Molecule'],
                            'State': row.get('State', 'neutral'),
                            'conformer': row.get('conformer', 'conf_1'),
                            'gap_type': 'S1-T1',  # 默认类型
                            'gap_value_ev': triplet_gap_data.loc[idx],
                            'gap_value_meV': triplet_gap_data.loc[idx] * 1000,
                            'gap_category': 'Inverted',
                            'source_column': 'triplet_gap_ev'
                        }
                        
                        # 添加分子特征
                        for col in self.feature_df.columns:
                            if col.startswith(('has_', 'estimated_', 'electron_', 'planarity')):
                                inverted_sample[col] = row.get(col, np.nan)
                        
                        all_inverted_samples.append(inverted_sample)
                        inverted_types_count['S1-T1'] = inverted_types_count.get('S1-T1', 0) + 1
            except Exception as e:
                print(f"处理 triplet_gap_ev 列时出错: {e}")
        
        # [继续原有的后续处理逻辑...]
        # 转换为DataFrame
        if all_inverted_samples:
            inverted_df = pd.DataFrame(all_inverted_samples)
            
            # 添加一些统计信息
            inverted_df['is_s1_t1'] = inverted_df['gap_type'] == 'S1-T1'
            inverted_df['is_higher_state'] = inverted_df['gap_type'].isin(['S2-T4', 'S3-T4', 'S4-T5'])
            
            # 按能隙值排序（最负的在前）
            inverted_df = inverted_df.sort_values('gap_value_ev')
            
            # 打印统计信息
            print(f"\n找到 {len(inverted_df)} 个反转能隙样本")
            print(f"反转类型分布:")
            for gap_type, count in inverted_types_count.items():
                print(f"  - {gap_type}: {count} 个样本")
            
            # 打印一些具体例子
            print(f"\n最显著的反转能隙（前10个）:")
            for idx, row in inverted_df.head(10).iterrows():
                print(f"  * {row['Molecule']} ({row['gap_type']}): {row['gap_value_ev']:.4f} eV ({row['gap_value_meV']:.1f} meV)")
            
            # [保持后续的正常样本获取和文件保存逻辑不变...]
            # 为了对比，也获取正常（非反转）样本
            normal_samples = []
            
            # 从相同的数据源获取正常样本
            gap_columns = []
            for col in self.feature_df.columns:
                if any(pattern in col.lower() for pattern in ['s1_t1', 's2_t4', 's3_t4', 'gap', 'singlet_triplet']):
                    if self.feature_df[col].dtype in ['float64', 'int64', 'float32', 'int32']:
                        gap_columns.append(col)
            
            for gap_col in gap_columns:
                try:
                    gap_data = pd.to_numeric(self.feature_df[gap_col], errors='coerce')
                    positive_mask = (gap_data > 0) & (gap_data.notna())
                    
                    # 限制正常样本数量
                    sample_size = min(max(10, len(inverted_df) // 2), positive_mask.sum())
                    if sample_size > 0:
                        positive_indices = self.feature_df.index[positive_mask].to_list()
                        sampled_indices = pd.Series(positive_indices).sample(n=sample_size, random_state=42).to_list()
                        
                        for idx in sampled_indices:
                            row = self.feature_df.loc[idx]
                            
                            # 使用新方法推断能隙类型
                            gap_type = self._infer_gap_type_from_column(gap_col)
                            
                            normal_sample = {
                                'Molecule': row['Molecule'],
                                'State': row.get('State', 'neutral'),
                                'conformer': row.get('conformer', 'conf_1'),
                                'gap_type': gap_type,
                                'gap_value_ev': gap_data.loc[idx],
                                'gap_value_meV': gap_data.loc[idx] * 1000,
                                'gap_category': 'Normal',
                                'source_column': gap_col
                            }
                            
                            # 添加分子特征
                            for col in self.feature_df.columns:
                                if col.startswith(('has_', 'estimated_', 'electron_', 'planarity')):
                                    normal_sample[col] = row.get(col, np.nan)
                            
                            normal_samples.append(normal_sample)
                            
                            if len(normal_samples) >= len(inverted_df):
                                break
                                
                except Exception as e:
                    print(f"处理正常样本时出错 ({gap_col}): {e}")
                    continue
                    
                if len(normal_samples) >= len(inverted_df):
                    break
            
            normal_df = pd.DataFrame(normal_samples) if normal_samples else pd.DataFrame()
            
            # 保存结果
            os.makedirs(self.output_dir, exist_ok=True)
            
            inverted_file = os.path.join(self.output_dir, "all_inverted_gap_samples.csv")
            inverted_df.to_csv(inverted_file, index=False)
            
            normal_file = os.path.join(self.output_dir, "normal_gap_samples.csv") 
            if not normal_df.empty:
                normal_df.to_csv(normal_file, index=False)
            
            # 合并文件用于分析
            all_gaps_df = pd.concat([inverted_df, normal_df], ignore_index=True) if not normal_df.empty else inverted_df
            all_gaps_file = os.path.join(self.output_dir, "all_gap_samples_analysis.csv")
            all_gaps_df.to_csv(all_gaps_file, index=False)
            
            print(f"\n文件已保存:")
            print(f"  - 反转能隙样本: {inverted_file}")
            if not normal_df.empty:
                print(f"  - 正常能隙样本: {normal_file}")
            print(f"  - 完整分析文件: {all_gaps_file}")
            
            return {
                'inverted_file': inverted_file,
                'normal_file': normal_file if not normal_df.empty else None,
                'all_gaps_file': all_gaps_file,
                'inverted_count': len(inverted_df),
                'normal_count': len(normal_df),
                'gap_types': inverted_types_count,
                'inverted_df': inverted_df,
                'normal_df': normal_df
            }
        
        else:
            print("未找到任何反转能隙样本")
            return None


    

    def print_feature_statistics(self):
        """Print comprehensive feature statistics"""
        if not hasattr(self, 'feature_df') or self.feature_df is None:
            return
        
        print("\n" + "="*60)
        print("FEATURE ENGINEERING STATISTICS")
        print("="*60)
        
        # Overall statistics
        print(f"\nTotal molecules: {len(self.feature_df)}")
        print(f"Total features: {len(self.feature_df.columns)}")
        
        # Feature categories
        feature_categories = {
            'Basic Properties': ['homo', 'lumo', 'dipole', 'energy'],
            'Structural Features': ['ring', 'size', 'complexity', 'planarity'],
            'Electronic Effects': ['electron_', 'polarity', 'hydrophobicity'],
            'Gap Features': ['_gap', 'inverted', 'inversion'],
            'Substituent Features': ['has_', '_count'],
            'Interaction Features': ['_x_', '_vs_', '_ratio'],
            'Categorical Features': ['_category', '_numeric', 'primary_inversion']
        }
        
        print("\nFeature Categories:")
        for category, keywords in feature_categories.items():
            count = 0
            features = []
            for col in self.feature_df.columns:
                if any(keyword in col for keyword in keywords):
                    count += 1
                    features.append(col)
            print(f"\n{category}: {count} features")
            if count > 0 and count <= 10:
                print(f"  Examples: {', '.join(features[:5])}" + ("..." if len(features) > 5 else ""))
        
        # Gap-specific statistics
        gap_columns = [col for col in self.feature_df.columns if col.endswith('_gap') and not col.endswith('_gap_meV')]
        print(f"\n\nGap-related features: {len(gap_columns)}")
        
        if gap_columns:
            print("\nGap types found:")
            for gap_col in sorted(gap_columns):
                non_null_count = self.feature_df[gap_col].notna().sum()
                if non_null_count > 0:
                    negative_count = (self.feature_df[gap_col] < 0).sum()
                    min_val = self.feature_df[gap_col].min()
                    max_val = self.feature_df[gap_col].max()
                    print(f"  {gap_col}: {non_null_count} molecules, {negative_count} negative gaps")
                    print(f"    Range: [{min_val:.3f}, {max_val:.3f}] eV")
        
        # Inversion statistics
        if 'num_inverted_gaps' in self.feature_df.columns:
            molecules_with_inversions = (self.feature_df['num_inverted_gaps'] > 0).sum()
            total_inversions = self.feature_df['num_inverted_gaps'].sum()
            max_inversions = self.feature_df['num_inverted_gaps'].max()
            
            print(f"\n\nInversion Statistics:")
            print(f"  Molecules with inverted gaps: {molecules_with_inversions}/{len(self.feature_df)} ({molecules_with_inversions/len(self.feature_df)*100:.1f}%)")
            print(f"  Total inversion instances: {total_inversions}")
            print(f"  Maximum inversions per molecule: {max_inversions}")
        
        # Most common inversion types
        if 'most_negative_gap_type' in self.feature_df.columns:
            gap_type_counts = self.feature_df['most_negative_gap_type'].value_counts()
            print("\n\nMost common primary inversion types:")
            for gap_type, count in gap_type_counts.head(10).items():
                if pd.notna(gap_type):
                    print(f"  {gap_type}: {count} molecules ({count/len(self.feature_df)*100:.1f}%)")
        
        # Mechanism distribution
        mechanism_cols = ['has_hRISC', 'has_inverted_ST', 'has_high_order_inversion', 'has_multi_channel']
        if all(col in self.feature_df.columns for col in mechanism_cols):
            print("\n\nMechanism Distribution:")
            for mech in mechanism_cols:
                count = self.feature_df[mech].sum()
                print(f"  {mech}: {count} molecules ({count/len(self.feature_df)*100:.1f}%)")
        
        print("\n" + "="*60)

    def get_feature_statistics(self):
        """Get comprehensive feature statistics as dictionary"""
        if not hasattr(self, 'feature_df') or self.feature_df is None:
            return None
        
        stats = {
            'total_features': len(self.feature_df.columns),
            'total_molecules': len(self.feature_df),
            'feature_categories': {},
            'gap_statistics': {},
            'inversion_statistics': {},
            'mechanism_distribution': {}
        }
        
        # Count features by category
        feature_categories = {
            'basic': len([c for c in self.feature_df.columns if any(k in c for k in ['homo', 'lumo', 'energy', 'dipole'])]),
            'structural': len([c for c in self.feature_df.columns if any(k in c for k in ['ring', 'size', 'complexity', 'planarity'])]),
            'electronic': len([c for c in self.feature_df.columns if any(k in c for k in ['electron_', 'polarity', 'hydrophobicity'])]),
            'gap_related': len([c for c in self.feature_df.columns if '_gap' in c]),
            'substituent': len([c for c in self.feature_df.columns if c.startswith('has_') or c.endswith('_count')]),
            'interaction': len([c for c in self.feature_df.columns if '_x_' in c or '_vs_' in c or '_ratio' in c]),
            'categorical': len([c for c in self.feature_df.columns if '_category' in c or 'primary_inversion' in c])
        }
        stats['feature_categories'] = feature_categories
        
        # Gap statistics
        gap_columns = [col for col in self.feature_df.columns if col.endswith('_gap') and not col.endswith('_gap_meV')]
        stats['gap_statistics']['num_gap_types'] = len(gap_columns)
        stats['gap_statistics']['gap_types'] = gap_columns
        
        # Inversion statistics
        if 'num_inverted_gaps' in self.feature_df.columns:
            stats['inversion_statistics']['molecules_with_inversions'] = (self.feature_df['num_inverted_gaps'] > 0).sum()
            stats['inversion_statistics']['total_inversions'] = self.feature_df['num_inverted_gaps'].sum()
            stats['inversion_statistics']['max_inversions_per_molecule'] = self.feature_df['num_inverted_gaps'].max()
            stats['inversion_statistics']['inversion_rate'] = stats['inversion_statistics']['molecules_with_inversions'] / len(self.feature_df)
        
        # Mechanism distribution
        mechanism_cols = ['has_hRISC', 'has_inverted_ST', 'has_high_order_inversion', 'has_multi_channel']
        for mech in mechanism_cols:
            if mech in self.feature_df.columns:
                stats['mechanism_distribution'][mech] = int(self.feature_df[mech].sum())
        
        # Most common gap types
        if 'most_negative_gap_type' in self.feature_df.columns:
            gap_type_counts = self.feature_df['most_negative_gap_type'].value_counts()
            stats['most_common_inversions'] = gap_type_counts.head(5).to_dict()
        
        return stats

    def save_feature_correlation_plot(self, feature_df, features_to_plot, output_dir):
        """保存特征相关性图"""
        # 确保输出目录存在
        os.makedirs(output_dir, exist_ok=True)
        
        # 创建相关性热图
        plt.figure(figsize=(10, 8))
        corr_matrix = feature_df[features_to_plot].corr()
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
        plt.title('Correlation Between Alternative 3D Features')
        
        # 明确保存图片
        output_path = os.path.join(output_dir, 'feature_correlation.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return output_path

    # 创建用于特征分布图的类似函数
    def save_feature_distribution_plots(self, feature_df, features_to_plot, output_dir):
        """保存特征分布图"""
        os.makedirs(output_dir, exist_ok=True)
        
        output_paths = []
        for feature in features_to_plot:
            plt.figure(figsize=(8, 5))
            sns.histplot(data=feature_df, x=feature, kde=True)
            plt.title(f'Distribution of {feature}')
            
            output_path = os.path.join(output_dir, f'{feature}_distribution.png')
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            output_paths.append(output_path)
        
        return output_paths

    def visualize_reversed_gaps(self):
        """可视化反转能隙分析结果"""
        if self.reversed_gap_df is None or len(self.reversed_gap_df) == 0:
            print("没有反转能隙数据可供可视化")
            return None
        
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        # 创建可视化输出目录
        viz_dir = os.path.join(self.output_dir, 'visualizations')
        os.makedirs(viz_dir, exist_ok=True)
        
        # 1. 反转能隙类型分布图
        plt.figure(figsize=(10, 6))
        gap_type_counts = self.reversed_gap_df['primary_gap_type'].value_counts()
        gap_type_counts.plot(kind='bar')
        plt.title('Distribution of Inverted Gap Types')
        plt.xlabel('Gap Type')
        plt.ylabel('Count')
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'gap_type_distribution.png'))
        plt.close()
        
        # 2. 反转能隙值分布
        plt.figure(figsize=(10, 6))
        plt.hist(self.reversed_gap_df['primary_gap_ev'], bins=20, edgecolor='black')
        plt.title('Distribution of Inverted Gap Values')
        plt.xlabel('Gap Value (eV)')
        plt.ylabel('Count')
        plt.axvline(x=0, color='red', linestyle='--', label='Zero Gap')
        plt.legend()
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'gap_value_distribution.png'))
        plt.close()
        
        # 3. 分类结果饼图
        if 'inversion_class' in self.reversed_gap_df.columns:
            plt.figure(figsize=(8, 8))
            class_counts = self.reversed_gap_df['inversion_class'].value_counts()
            plt.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%')
            plt.title('Inverted Gap Classification')
            plt.tight_layout()
            plt.savefig(os.path.join(viz_dir, 'gap_classification.png'))
            plt.close()
        
        print(f"可视化结果已保存到: {viz_dir}")
        return viz_dir

    def run_feature_pipeline(self, data_file=None):
            """Run the complete feature engineering pipeline."""
            if data_file:
                self.load_data(data_file)
            elif self.data_file:
                self.load_data()
            else:
                self.logger.error("No data file specified.")
                return False
            
            # 1. Generate basic molecular descriptors
            print("Step 1: Generating molecular descriptors...")
            self.generate_molecular_descriptors()
            
            # 2. Extract alternative 3D features
            print("Step 2: Extracting alternative 3D features...")
            self.extract_alternative_3d_features()
            
            # 3. Extract all types of reversed gap features
            print("Step 3: Extracting reversed gap features...")
            reversed_gap_df = self.extract_reversed_gap_features()
            
            # 4. Integrate all features into feature_df
            if reversed_gap_df is not None and len(reversed_gap_df) > 0:
                print(f"Found {len(reversed_gap_df)} molecules with gap data")
                # Merge reversed gap features into main feature_df
                if hasattr(self, 'feature_df') and self.feature_df is not None:
                    self.feature_df = pd.merge(
                        self.feature_df,
                        reversed_gap_df,
                        on='Molecule',
                        how='left',
                        suffixes=('', '_gap')
                    )
                    # Remove duplicate columns
                    self.feature_df = self.feature_df.loc[:, ~self.feature_df.columns.duplicated()]
                    print(f"Merged reversed gap features. Total features: {len(self.feature_df.columns)}")
            
            # 5. Add gap interaction features
            print("Step 4: Creating gap interaction features...")
            if hasattr(self, 'feature_df') and self.feature_df is not None:
                self.feature_df = self.add_gap_interaction_features(self.feature_df)
                
            # 6. Create categorical gap features
            print("Step 5: Creating categorical gap features...")
            if hasattr(self, 'feature_df') and self.feature_df is not None:
                self.feature_df = self.create_categorical_gap_features(self.feature_df)
            
            # 7. Compute derived features (including new gap interactions)
            print("Step 6: Computing derived features...")
            self.compute_derived_features()
            
            # 8. Preprocess data and save
            print("Step 7: Preprocessing and saving features...")
            feature_file = self.preprocess_data()
            
            # 9. Extract negative S1-T1 gap samples (for backward compatibility)
            print("Step 8: Extracting S1-T1 gap samples for backward compatibility...")
            gap_data = self.get_negative_s1t1_samples()
            
            # 10. Extract all types of inverted gap samples
            print("Step 9: Extracting all inverted gap samples...")
            all_inverted_gaps = self.get_all_inverted_gap_samples()
            
            # 11. Classify and visualize inverted gaps
            visualization_results = None
            if all_inverted_gaps is not None and len(all_inverted_gaps) > 0:
                print("Step 10: Classifying and visualizing inverted gaps...")
                self.classify_inverted_gaps()
                visualization_results = self.visualize_reversed_gaps()
            
            # 12. Save enhanced feature file (with all gap information)
            enhanced_feature_file = feature_file.replace('.csv', '_enhanced.csv')
            if hasattr(self, 'feature_df') and self.feature_df is not None:
                self.feature_df.to_csv(enhanced_feature_file, index=False)
                print(f"Saved enhanced features to: {enhanced_feature_file}")
                print(f"Total number of features: {len(self.feature_df.columns)}")
                
                # Print feature statistics
                self.print_feature_statistics()
            
            return {
                'feature_file': feature_file,  # Original feature file
                'enhanced_feature_file': enhanced_feature_file,  # Enhanced feature file
                'gap_data': gap_data,  # S1-T1 only (backward compatibility)
                'all_inverted_gaps': all_inverted_gaps,  # All types of inversions
                'reversed_gap_features': reversed_gap_df,  # Reversed gap features DataFrame
                'visualization_results': visualization_results,  # Visualization results
                'feature_statistics': self.get_feature_statistics() if hasattr(self, 'feature_df') else None
            }
